<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Neel Guha | Home</title>
  <meta name="description" content="Homepage of Neel Guha">
  <meta name="author" content="Neel Guha">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href=/libs/custom/my_css.css>
  <link rel="stylesheet" href=/stylesheet.css>

  <!-- Font-Awesome -->
  <link rel="stylesheet" href=/libs/external/font-awesome-4.7.0/css/font-awesome.min.css>

  <!-- Academicons -->
  <link rel="stylesheet" href=/libs/external/academicons-1.9.4/css/academicons.min.css>

  <!-- JQuery -->
  <script src=/libs/external/jquery-3.1.1.min.js></script>
  <script src=/libs/custom/my_js.js></script>
</head>
<body>
  <div class="wrapper">
    <aside class="sidebar">
      <img src='/assets/profile-pics/prof_pic.jpg' alt="Profile" class="profile-img">
      <h1>Neel Guha</h1>
      
      <nav>
        <a class="" href=/index.html>Bio</a>
        <a class="" href=/publications.html>Publications</a>
        <a class="" href=/blog.html>Blog</a>
        <a class="" href=/code.html>Code and data</a>
        <a class="" href=/contact.html>Contact</a>
        <a class="" href=/assets/pdf/Neel_Guha_CV.pdf>CV</a>
      </nav>
    </aside>
    
    <main class="main-content">
      <div class="highlight-box">
  <strong>I'm currently on the legal academic job market!</strong> My job market paper is about how technical differences in AI across different applications---e.g., self-driving cars, legal aid chatbots, etc.---should influence the design of AI regulation in each of these contexts. My different materials (CV, research statement, job market paper) are available on request!
</div>

<p>
  I am a sixth year JD-PhD student in Computer Science at Stanford University (advised by <a href="https://cs.stanford.edu/~chrismre/">Chris RÃ©</a>). I'm affiliated with <a href="https://hazyresearch.stanford.edu/">Hazy Research Lab</a>, the <a href="https://crfm.stanford.edu/">Stanford Center for Research on Foundation Models</a>, <a href="https://reglab.stanford.edu/">RegLab</a>, and <a href="https://liftlab.stanford.edu/">liftlab</a>. I graduated with a MS in Machine Learning from Carnegie Mellon University ('19) and a BS (with Honors) in Computer Science from Stanford University ('18). I am grateful to be supported by the <a href="https://vpge.stanford.edu/fellowships-funding/sigf">Stanford Interdisciplinary Graduate Fellowship (SIGF)</a> and the <a href= "https://hai.stanford.edu/news/stanford-hai-welcomes-graduate-postdoc-fellows">HAI Graduate Fellowship</a>. 
</p>

<p>
  I have published in a range of venues, incuding traditional peer-reviewed machine learning/AI conferences (ICML, NeurIPS, ICLR, etc.), law reviews (George Washingon, UPenn, Wisconsin, Harvard JOLT), and medical journals (NEJM, JAMA). Please see my <a href="publications.html">publications</a> page for a complete list.
</p>

<h2>Research</h2>
<p>My research lies at the intersection of artificial intelligence/machine learning (AI/ML) and law. Most of my work can be organized into four buckets:</p>

<ul class="custom-list">
  <li>
    <strong>Using machine learning to study the law and legal institutions.</strong> ML provides a useful set of techniques to perform large scale analysis of different legal corpora---cases, statutes, regulations, and more. I apply these techniques in the context of different substantive legal questions (often with a focus on civil procedure). For instance, my prior work has tested theories of private enforcement  at the state level, by building a database of state private rights of action <a href="https://scholarship.law.upenn.edu/penn_law_review/vol172/iss1/2/">(U. Pa. L. Rev. 2024)</a>. In <a href="https://wlr.law.wisc.edu/wp-content/uploads/sites/1263/2024/11/8-Guha-Zambrano-Camera-Ready.pdf">ongoing work</a>, I am extending these techniques to build an open and accessible database of state laws, annotated with a broad spectrum of relevant features. 
  </li>
  <li>
    <strong>Studying questions around AI governance.</strong> I'm interested in how technical nuances of AI affect governance. 
    My recent work has examined trends in how courts have approached liability for medical AI <a href="https://www.nejm.org/doi/full/10.1056/NEJMhle2308901?query=featured_home">(NEJM 2024)</a>, and the technical and institutional trade-offs of commonly proposed regulatory interventions
    <a href="https://dho.stanford.edu/wp-content/uploads/AI_Regulation.pdf">(GW L. Rev. 2024)</a>. In an ongoing project, I am examining how informational and structural properties of AI applications influence regulatory design across different application/use-contexts.
  </li>
  <li>
    <strong>Measuring the legal usefulness/capabilities of large language models (LLMs).</strong> I work on building benchmarks to assess how well LLMs can perform different legal tasks. Measurement on legal tasks serves as a useful proxy for assessing reasoning capabilities generally, and also clarifies opportunities for real-world use. Examples of this work include 
    <a href="https://hazyresearch.stanford.edu/legalbench/">LegalBench</a> (NeurIPS 2023), 
    <a href="http://arxiv.org/abs/2104.08671">CaseHOLD</a> (ICAIL 2021), 
    <a href="https://reglab.github.io/legal-rag-benchmarks/">RAG benchmarks</a> (CS&Law 2025), and 
    <a href="https://arxiv.org/abs/2402.07440">LoCo</a> (ICML 2024).
  </li>
  <li>
    <strong>Improving LLM performance when labeled data is scarce.</strong> Producing labeled data for tasks is often expensive or impractical. I've studied how information contained within other prexisting sources may be extracted and leveraged to improve model performance for specific tasks. Examples of auxiliary sources of information include pretrained embedding models (e.g., BERT), and knowledge bases (e.g., Freebase, Wikipedia). Examples of this work include 
    <a href="https://arxiv.org/abs/2412.04692">Smoothie</a> (NeurIPS 2024), 
    <a href="http://arxiv.org/abs/2307.11031">Embroid</a> (NeurIPS 2023), and 
    <a href="https://www.cidrdb.org/cidr2021/papers/cidr2021_paper13.pdf">Bootleg</a> (CIDR 2021).
  </li>
</ul>

<h2>Recent News</h2>
<div class="news-grid">
  
  
    <div class="news-item">
      <div class="news-date">June 2025</div>
      <div class="news-text">Our <a href='https://academic.oup.com/edited-volume/59908/chapter-abstract/523978823?redirectedFrom=fulltext'>chapter</a> on legal benchmarking in the Oxford Handbook on the Foundations and Regulation of Generative AI is out!</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">June 2025</div>
      <div class="news-text">We've released <a href='https://hazyresearch.stanford.edu/blog/2025-06-08-cartridges'>Cartridges</a>, a new self-study framework for building long context representations for LLMs. Check out the <a href='https://github.com/HazyResearch/cartridges'>code</a> and <a href='https://arxiv.org/abs/2506.06266'>paper</a>!</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">March 2025</div>
      <div class="news-text">We've built two new benchmarks for evaluating legal RAG systems--on both housing law and bar exam-esque questions! It's forthcoming at <a href='https://computersciencelaw.org/2025/'>CS&Law 2025</a>, and you can check out the work <a href='https://reglab.github.io/legal-rag-benchmarks/'>here</a>.</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">January 2025</div>
      <div class="news-text">Spoke on a panel at the <a href='https://na.eventscloud.com/website/79050/'>Access to Justice and AI: New Frontiers for Research, Policy, and Practice</a> (with David Engstrom, Gillian Hadfield, Natalie Knowlton, and Zach Zarnow) about evaluation in the A2J context.</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">December 2024</div>
      <div class="news-text"><a href='https://www.gwlr.org/vol-92-no-6/'>AI Regulation Has Its Own Alignment Problem</a> officially out in the George Washington Law Review.</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">November 2024</div>
      <div class="news-text">Diego Zambrano and I have a <a href='https://wlr.law.wisc.edu/wp-content/uploads/sites/1263/2024/11/8-Guha-Zambrano-Camera-Ready.pdf'>short piece</a> out in the Wisconsin Law Review talking about a new empirical project that uses LLMs to build an annotated database of state statutes!</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">October 2024</div>
      <div class="news-text">Michelle Mello and I appeared on the <a href='https://law.stanford.edu/stanford-legal-podcast/exploring-ai-in-healthcare-legal-regulatory-and-safety-challenges/'>Stanford Legal Podcast</a> (hosted by Professor Pam Karlan and Professor Rich Ford) to talk about our work on AI liability in healthcare.</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">September 2024</div>
      <div class="news-text">Work on <a href='https://arxiv.org/abs/2412.04692'>learning unsupervised routers</a> for LLMs accepted to NeurIPS 2024.</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">July 2024</div>
      <div class="news-text"><a href='https://arxiv.org/abs/2407.14981'>Open Problems in Technical AI Governance</a> out on ArXiv.</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">May 2024</div>
      <div class="news-text">Excited to contribute a <a href='https://neelguha.github.io/assets/pdf/building_genai_benchmarks_for_law_oxford_chapter.pdf'>chapter</a> on benchmarking language models for legal applications to The Oxford Handbook on the Foundations and Regulation of Generative AI (OUP, 2024).</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">May 2024</div>
      <div class="news-text">Two papers accepted to ICML 2024: (1) <a href='https://arxiv.org/abs/2402.11729'>Prospectors</a>, and (2) <a href='https://arxiv.org/abs/2402.07440'>Long-Context Retrievers</a>.</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">January 2024</div>
      <div class="news-text"><a href='https://www.nejm.org/doi/full/10.1056/NEJMhle2308901?query=featured_home'>Understanding Liability Risk from Using Health Care Artificial Intelligence Tools</a> out in The New England Journal of Medicine (with Michelle Mello).</div>
    </div>
  
    <div class="news-item">
      <div class="news-date">January 2024</div>
      <div class="news-text"><a href='https://scholarship.law.upenn.edu/penn_law_review/vol172/iss1/2/'>Private Enforcement in the States</a> out in University of Pennsylvania Law Review (with Diego Zambrano, Austin Peters, and Jeffrey Xia).</div>
    </div>
  
</div>


    </main>
  </div>
</body>
</html>
