---
layout: default
title: Home
---
<div class="docs-section" id="bio">
  <p>
    <b>
    I'm currently on the legal academic job market! My job market paper is about how technical differences in AI across different applications---e.g., self-driving cars, legal aid chatbots, etc.---should influence the design of AI regulation in each of these contexts. My different materials (CV, research statement, job market paper) are available on request!
  </b>
  </p>
<p>
    I am a sixth year JD-PhD student in Computer Science at Stanford University (advised by <a href="https://cs.stanford.edu/~chrismre/">Chris RÃ©</a>). I'm a part of the <a href="https://hazyresearch.stanford.edu/">Hazy Research Lab</a>, <a href="https://crfm.stanford.edu/">Stanford Center for Research on Foundation Models</a>, and <a href="https://reglab.stanford.edu/">RegLab</a>. I graduated with a MS in Machine Learning from Carnegie Mellon University ('19) and a BS (with Honors) in Computer Science from Stanford University ('18). I am grateful to be supported by the <a href="https://vpge.stanford.edu/fellowships-funding/sigf">Stanford Interdisciplinary Graduate Fellowship (SIGF)</a> and the <a href= "https://hai.stanford.edu/news/stanford-hai-welcomes-graduate-postdoc-fellows">HAI Graduate Fellowship</a>. 
</p>
<p>
My research lies at the intersection of artificial intelligence/machine learning (AI/ML) and law. Most of my work can be organized into four buckets:
</p>
<style>
  .custom-list {
    list-style-type: none; /* Remove default bullet points */
    margin-left: 40px;
    color: #333; /* Darker color for bullets */
  }
  .custom-list li::before {
      content: "\25B6"; /* Unicode for a triangle */
      color: #333;
      display: inline-block;
      width: 1em;
      margin-left: -1em;
    }
</style>
<p>

<ul class="custom-list">
  <li>
    <b>Using machine learning to study the law and legal institutions.</b> ML provides a useful set of techniques to perform large scale analysis of different legal corpora---cases, statutes, regulations, and more. I apply these techniques in the context of different substantive legal questions (often with a focus on civil procedure). For instance, my prior work has tested theories of private enforcement  at the state level, by building a database of state private rights of action <a href="https://scholarship.law.upenn.edu/penn_law_review/vol172/iss1/2/">(U. Pa. L. Rev. 2024)</a>. In <a href="https://wlr.law.wisc.edu/wp-content/uploads/sites/1263/2024/11/8-Guha-Zambrano-Camera-Ready.pdf">ongoing work</a>, I am extending these techniques to build an open and accessible database of state laws, annotated with a broad spectrum of relevant features. 
  </li>
  <li>
      <b>Studying questions around AI governance.</b> I'm interested in how technical nuances of AI affect governance. 
      My recent work has examined trends in how courts have approached liability for medical AI <a href="https://www.nejm.org/doi/full/10.1056/NEJMhle2308901?query=featured_home">(NEJM 2024)</a>, and the technical and institutional trade-offs of commonly proposed regulatory interventions
      <a href="https://dho.stanford.edu/wp-content/uploads/AI_Regulation.pdf">(GW L. Rev. 2024)</a>. In an ongoing project, I am examining how informational and structural properties of AI applications influence regulatory design across different application/use-contexts.
  </li>
  <li>
      <b>Measuring the legal usefulness/capabilities of large language models (LLMs).</b> I work on building benchmarks to assess how well LLMs can perform different legal tasks. Measurement on legal tasks serves as a useful proxy for assessing reasoning capabilities generally, and also clarifies opportunities for real-world use. Examples of this work include 
      <a href="https://hazyresearch.stanford.edu/legalbench/">LegalBench</a> (NeurIPS 2023), 
      <a href="http://arxiv.org/abs/2104.08671">CaseHOLD</a> (ICAIL 2021), 
      <a href="https://reglab.github.io/legal-rag-benchmarks/">RAG benchmarks</a> (CS&Law 2025), and 
      <a href="https://arxiv.org/abs/2402.07440">LoCo</a> (ICML 2024).
  </li>
  <li>
      <b>Improving LLM performance when labeled data is scarce.</b> Producing labeled data for tasks is often expensive or impractical. I've studied how information contained within other prexisting sources may be extracted and leveraged to improve model performance for specific tasks. Examples of auxiliary sources of information include pretrained embedding models (e.g., BERT), and knowledge bases (e.g., Freebase, Wikipedia). Examples of this work include 
      <a href="https://arxiv.org/abs/2412.04692">Smoothie</a> (NeurIPS 2024), 
      <a href="http://arxiv.org/abs/2307.11031">Embroid</a> (NeurIPS 2023), and 
      <a href="https://www.cidrdb.org/cidr2021/papers/cidr2021_paper13.pdf">Bootleg</a> (CIDR 2021).
  </li>
</ul>
</p>
</div>

<div class="docs-section" id="news">
  <style>
    .news-grid {
      display: grid;
      grid-template-columns: auto 1fr;
      gap: 1rem;
    }
    .news-time {
      white-space: wrap;
    }
    .news-event {
      overflow: hidden;
      text-overflow: ellipsis;
      white-space: wrap;
    }
  </style>
  
  <h4>Recent News</h4>
  <div class="news-grid">
    {% assign current_talks = site.data.news.news | where: "category", "current" %}
    {% for talk in current_talks %}
      <b class="news-time">{{ talk.time }}</b>
      <span class="news-event">{{ talk.events }}</span>
    {% endfor %}
  </div>
  
<div class="docs-section" id="ack">
<p>
  Website design and template by <a href="https://github.com/msaveski/www_personal">Martin Saveski</a>.
</p>
